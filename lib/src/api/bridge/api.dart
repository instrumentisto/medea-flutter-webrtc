// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.10.0.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';

import 'api/media_stream_track.dart';
import 'api/media_stream_track/media_type.dart';
import 'api/peer_connection_event.dart';
import 'api/peer_connection_event/ice_connection_state.dart';
import 'api/peer_connection_event/ice_gathering_state.dart';
import 'api/peer_connection_event/peer_connection_state.dart';
import 'api/peer_connection_event/rtc_track_event.dart';
import 'api/peer_connection_event/signaling_state.dart';
import 'api/rtc_configuration.dart';
import 'api/rtc_configuration/bundle_policy.dart';
import 'api/rtc_configuration/ice_transports_type.dart';
import 'api/rtc_configuration/rtc_ice_server.dart';
import 'api/rtc_rtp_encoding_parameters.dart';
import 'api/rtc_rtp_send_parameters.dart';
import 'api/rtc_rtp_transceiver.dart';
import 'api/rtc_session_description.dart';
import 'api/rtp_transceiver_init.dart';
import 'frb_generated.dart';
import 'lib.dart';

// These types are ignored because they are neither used by any `pub` functions nor (for structs and enums) marked `#[frb(unignore)]`: `TrackKind`
// These function are ignored because they are on traits that is not defined in current crate (put an empty `#[frb]` on it to unignore): `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `clone`, `eq`, `eq`, `fmt`, `fmt`, `from`, `from`, `from`, `hash`

/// Configures media acquisition to use fake devices instead of actual camera
/// and microphone.
Future<void> enableFakeMedia() =>
    RustLib.instance.api.crateApiEnableFakeMedia();

/// Indicates whether application is configured to use fake media devices.
Future<bool> isFakeMedia() => RustLib.instance.api.crateApiIsFakeMedia();

/// Creates a new [`PeerConnection`] and returns its ID.
Stream<PeerConnectionEvent> createPeerConnection({
  required RtcConfiguration configuration,
}) => RustLib.instance.api.crateApiCreatePeerConnection(
  configuration: configuration,
);

/// Initiates the creation of an SDP offer for the purpose of starting a new
/// WebRTC connection to a remote peer.
Future<RtcSessionDescription> createOffer({
  required ArcPeerConnection peer,
  required bool voiceActivityDetection,
  required bool iceRestart,
  required bool useRtpMux,
}) => RustLib.instance.api.crateApiCreateOffer(
  peer: peer,
  voiceActivityDetection: voiceActivityDetection,
  iceRestart: iceRestart,
  useRtpMux: useRtpMux,
);

/// Creates an SDP answer to an offer received from a remote peer during an
/// offer/answer negotiation of a WebRTC connection.
Future<RtcSessionDescription> createAnswer({
  required ArcPeerConnection peer,
  required bool voiceActivityDetection,
  required bool iceRestart,
  required bool useRtpMux,
}) => RustLib.instance.api.crateApiCreateAnswer(
  peer: peer,
  voiceActivityDetection: voiceActivityDetection,
  iceRestart: iceRestart,
  useRtpMux: useRtpMux,
);

/// Replaces the specified [`AudioTrack`] (or [`VideoTrack`]) on the
/// [`sys::RtpTransceiverInterface`]'s `sender`.
///
/// [`AudioTrack`]: crate::AudioTrack
/// [`VideoTrack`]: crate::VideoTrack
Future<void> senderReplaceTrack({
  required ArcPeerConnection peer,
  required ArcRtpTransceiver transceiver,
  String? trackId,
}) => RustLib.instance.api.crateApiSenderReplaceTrack(
  peer: peer,
  transceiver: transceiver,
  trackId: trackId,
);

/// Returns [`RtpParameters`] from the provided [`RtpTransceiver`]'s `sender`.
Future<RtcRtpSendParameters> senderGetParameters({
  required ArcRtpTransceiver transceiver,
}) =>
    RustLib.instance.api.crateApiSenderGetParameters(transceiver: transceiver);

/// Sets [`RtpParameters`] into the provided [`RtpTransceiver`]'s `sender`.
Future<void> senderSetParameters({
  required ArcRtpTransceiver transceiver,
  required RtcRtpSendParameters params,
}) => RustLib.instance.api.crateApiSenderSetParameters(
  transceiver: transceiver,
  params: params,
);

/// Adds the new ICE `candidate` to the given [`PeerConnection`].
Future<void> addIceCandidate({
  required ArcPeerConnection peer,
  required String candidate,
  required String sdpMid,
  required int sdpMlineIndex,
}) => RustLib.instance.api.crateApiAddIceCandidate(
  peer: peer,
  candidate: candidate,
  sdpMid: sdpMid,
  sdpMlineIndex: sdpMlineIndex,
);

/// Tells the [`PeerConnection`] that ICE should be restarted.
Future<void> restartIce({required ArcPeerConnection peer}) =>
    RustLib.instance.api.crateApiRestartIce(peer: peer);

/// Closes the [`PeerConnection`].
Future<void> disposePeerConnection({required ArcPeerConnection peer}) =>
    RustLib.instance.api.crateApiDisposePeerConnection(peer: peer);

/// Sets the specified `audio playout` device.
Future<void> setAudioPlayoutDevice({required String deviceId}) =>
    RustLib.instance.api.crateApiSetAudioPlayoutDevice(deviceId: deviceId);

/// Indicates whether the microphone is available to set volume.
Future<bool> microphoneVolumeIsAvailable() =>
    RustLib.instance.api.crateApiMicrophoneVolumeIsAvailable();

/// Sets the microphone system volume according to the specified `level` in
/// percents.
///
/// Valid values range is `[0; 100]`.
Future<void> setMicrophoneVolume({required int level}) =>
    RustLib.instance.api.crateApiSetMicrophoneVolume(level: level);

/// Returns the current level of the microphone volume in `[0; 100]` range.
Future<int> microphoneVolume() =>
    RustLib.instance.api.crateApiMicrophoneVolume();

/// Sets the provided `OnDeviceChangeCallback` as the callback to be called
/// whenever a set of available media devices changes.
///
/// Only one callback can be set at a time, so the previous one will be dropped,
/// if any.
Stream<void> setOnDeviceChanged() =>
    RustLib.instance.api.crateApiSetOnDeviceChanged();

/// Transport protocols used in [WebRTC].
///
/// [WebRTC]: https://w3.org/TR/webrtc
enum Protocol {
  /// [Transmission Control Protocol][1].
  ///
  /// [1]: https://en.wikipedia.org/wiki/Transmission_Control_Protocol
  tcp,

  /// [User Datagram Protocol][1].
  ///
  /// [1]: https://en.wikipedia.org/wiki/User_Datagram_Protocol
  udp,
}

/// [ScalabilityMode][0] representation.
///
/// [0]: https://tinyurl.com/35ae3mbe
enum ScalabilityMode {
  /// [ScalabilityMode.L1T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L1T1*
  l1T1,

  /// [ScalabilityMode.L1T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L1T2*
  l1T2,

  /// [ScalabilityMode.L1T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L1T3*
  l1T3,

  /// [ScalabilityMode.L2T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T1*
  l2T1,

  /// [ScalabilityMode.L2T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T1*
  l2T1H,

  /// [ScalabilityMode.L2T1_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T1_KEY*
  l2T1Key,

  /// [ScalabilityMode.L2T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2h*
  l2T2,

  /// [ScalabilityMode.L2T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2*
  l2T2H,

  /// [ScalabilityMode.L2T2_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2_KEY*
  l2T2Key,

  /// [ScalabilityMode.L2T2_KEY_SHIFT][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2_KEY_SHIFT*
  l2T2KeyShift,

  /// [ScalabilityMode.L2T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T3*
  l2T3,

  /// [ScalabilityMode.L2T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T3*
  l2T3H,

  /// [ScalabilityMode.L2T3_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T3_KEY*
  l2T3Key,

  /// [ScalabilityMode.L3T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T1*
  l3T1,

  /// [ScalabilityMode.L3T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T1*
  l3T1H,

  /// [ScalabilityMode.L3T1_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T1_KEY*
  l3T1Key,

  /// [ScalabilityMode.L3T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T2h*
  l3T2,

  /// [ScalabilityMode.L3T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T2*
  l3T2H,

  /// [ScalabilityMode.L3T2_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T2_KEY*
  l3T2Key,

  /// [ScalabilityMode.kL3T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kL3T3*
  l3T3,

  /// [ScalabilityMode.kL3T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kL3T3*
  l3T3H,

  /// [ScalabilityMode.kL3T3_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T3_KEY*
  l3T3Key,

  /// [ScalabilityMode.kS2T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T1*
  s2T1,

  /// [ScalabilityMode.kS2T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T1*
  s2T1H,

  /// [ScalabilityMode.kS2T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T2*
  s2T2,

  /// [ScalabilityMode.kS2T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T2*
  s2T2H,

  /// [ScalabilityMode.S2T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S2T3h*
  s2T3,

  /// [ScalabilityMode.S2T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S2T3*
  s2T3H,

  /// [ScalabilityMode.S3T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T1*
  s3T1,

  /// [ScalabilityMode.S3T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T1*
  s3T1H,

  /// [ScalabilityMode.S3T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T2*
  s3T2,

  /// [ScalabilityMode.S3T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T2*
  s3T2H,

  /// [ScalabilityMode.S3T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T3*
  s3T3,

  /// [ScalabilityMode.S3T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T3*
  s3T3H,
}
